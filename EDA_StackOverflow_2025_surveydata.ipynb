{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqbF3YCD4KWWDngL4sdeZ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harish-lvrk/Data-Analysis-project/blob/main/EDA_StackOverflow_2025_surveydata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1Am4WgjbC6b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "911cc063"
      },
      "source": [
        "# üìä EDA Case Study: Stack Overflow Annual Developer Survey 2020\n",
        "\n",
        "## üë®‚Äçüíª Author\n",
        "**L Hareesh**  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Project Overview\n",
        "\n",
        "This project performs **Exploratory Data Analysis (EDA)** on the **Stack Overflow Annual Developer Survey 2025 dataset**.  \n",
        "The dataset contains responses from **65,000+ developers worldwide**, where they shared details about their age, countries, education, jobs, salaries, programming languages, and preferences.\n",
        "\n",
        "The main goal is to analyze and visualize the data to understand **global developer trends in 2020**.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Understanding the Title\n",
        "\n",
        "### üîπ What is Stack Overflow?\n",
        "A popular website where programmers ask and answer coding questions.\n",
        "\n",
        "### üîπ What is the Annual Developer Survey?\n",
        "Every year, Stack Overflow collects responses from developers worldwide about their demographics, skills, and work.\n",
        "\n",
        "### üîπ What are Responses?\n",
        "Each respondent (developer) provides answers. Example:\n",
        "\n",
        "* Question: *What programming languages do you use?*  \n",
        "* Response: *Python, JavaScript, SQL*\n",
        "\n",
        "### üîπ What does Analyzing Responses mean?\n",
        "Studying those answers to find insights like:\n",
        "\n",
        "* Most popular programming languages  \n",
        "* Average salaries by country  \n",
        "* Work preferences during COVID-19 (2020)\n",
        "\n",
        "### üîπ Where does the Data come from?\n",
        "Published by **Stack Overflow**, freely available on their research page or Kaggle.\n",
        "\n",
        "---\n",
        "\n",
        "## üí° What You Can Do with the Data\n",
        "\n",
        "1. **Demographics** ‚Äì Age, gender, countries of developers.  \n",
        "2. **Programming Languages & Tools** ‚Äì Most popular languages, databases, frameworks.  \n",
        "3. **Job & Salary Analysis** ‚Äì Salary by country, experience, education.  \n",
        "4. **Learning & Education** ‚Äì University vs self-taught vs bootcamp.  \n",
        "5. **Work Preferences** ‚Äì Remote work, job satisfaction, working hours.  \n",
        "6. **Trends & Patterns** ‚Äì Younger vs older developers, technology shifts.  \n",
        "7. **Advanced Analysis** ‚Äì Correlations, clustering, deeper insights.  \n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Roadmap for EDA\n",
        "\n",
        "### **Step 1: Load the Data**\n",
        "* Import libraries (`pandas`, `matplotlib`, `seaborn`)  \n",
        "* Load dataset with `pd.read_csv()`  \n",
        "* Check shape (rows, columns) and first few rows  \n",
        "\n",
        "---\n",
        "\n",
        "### **Step 2: Understand the Data**\n",
        "* `df.info()` ‚Üí Column names & datatypes  \n",
        "* `df.describe()` ‚Üí Summary stats  \n",
        "* `df.isnull().sum()` ‚Üí Missing values  \n",
        "\n",
        "---\n",
        "\n",
        "### **Step 3: Clean the Data**\n",
        "* Remove irrelevant columns (IDs, metadata)  \n",
        "* Handle missing values (drop/fill)  \n",
        "* Rename columns (e.g., `YearsCodePro ‚Üí Years_Professional`)  \n",
        "* Convert text into numeric values where needed  \n",
        "\n",
        "---\n",
        "\n",
        "### **Step 4: Demographics**\n",
        "* Age distribution (histogram)  \n",
        "* Top countries by respondents  \n",
        "* Gender distribution  \n",
        "\n",
        "---\n",
        "\n",
        "### **Step 5: Programming Languages & Tools**\n",
        "* Most popular programming languages (bar chart)  \n",
        "* Databases, frameworks, cloud platforms analysis  \n",
        "\n",
        "---\n",
        "\n",
        "### **Step 6: Job & Salary**\n",
        "* Salary distribution (boxplot)  \n",
        "* Salary by country  \n",
        "* Salary vs years of experience  \n",
        "* Salary vs education level  \n",
        "\n",
        "---\n",
        "\n",
        "### **Step 7: Learning & Education**\n",
        "* Coding learning methods (bootcamp, university, self-taught)  \n",
        "* Education level vs salary  \n",
        "* Education level vs languages used  \n",
        "\n",
        "---\n",
        "\n",
        "### **Step 8: Work Preferences**\n",
        "* Remote work preference (important in 2020 ‚Äì pandemic)  \n",
        "* Job satisfaction levels  \n",
        "* Weekly working hours  \n",
        "\n",
        "---\n",
        "\n",
        "### **Step 9: Correlation & Multivariate Analysis**\n",
        "* Correlation heatmap (experience, age, salary)  \n",
        "* Salary vs Experience scatterplot  \n",
        "* Grouping developers by skills (optional clustering)  \n",
        "\n",
        "---\n",
        "\n",
        "### **Step 10: Summarize Insights**\n",
        "* Top 3 languages: **JavaScript, Python, SQL**  \n",
        "* **US developers** earn highest salaries; **India** has more developers but lower median salary  \n",
        "* Younger developers ‚Üí Python; Older developers ‚Üí Java, C#  \n",
        "* Rise of self-taught developers  \n",
        "\n",
        "---\n",
        "\n",
        "## üîë Final Summary\n",
        "\n",
        "This project analyzes the **Stack Overflow 2020 Developer Survey** to uncover:\n",
        "\n",
        "* Who the developers are  \n",
        "* What tools they use  \n",
        "* How much they earn  \n",
        "* How they learn coding  \n",
        "* How their preferences changed in 2020 (COVID-19 year)  \n",
        "\n",
        "It helps us **understand global trends in software development**.  \n",
        "\n",
        "---\n",
        "\n",
        "## üôå Acknowledgements\n",
        "* Dataset Source: [Stack Overflow Developer Survey 2025](https://insights.stackoverflow.com/survey)  \n",
        "* Analysis & Documentation: **L Hareesh**  \n",
        "* AI Assistance: **ChatGPT**  **Gemini Pro**\n",
        "\n",
        "---\n",
        "\n",
        "## üìö References & Resources\n",
        "\n",
        "* [Google Colab](https://colab.research.google.com/) ‚Äì Cloud-based Python environment used for running the analysis.  \n",
        "* [Pandas Documentation](https://pandas.pydata.org/) ‚Äì Python data analysis library.  \n",
        "* [NumPy Documentation](https://numpy.org/) ‚Äì Numerical computing library.  \n",
        "* [Matplotlib Documentation](https://matplotlib.org/) ‚Äì Visualization library.  \n",
        "* [Seaborn Documentation](https://seaborn.pydata.org/) ‚Äì Statistical data visualization.  \n",
        "* [YouTube Playlist: Pandas & NumPy Tutorials](https://www.youtube.com/watch?v=GPVsHOlRBBI&list=PLyMom0n-MBrpr1Q3OQC5Od1o1zczHEO0u) ‚Äì Helpful for learning data manipulation and analysis.  \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cw2yzAUye7Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9522364f"
      },
      "source": [
        "# Install the necessary library for downloading files from GitHub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7316ddba",
        "outputId": "ec0b2918-91b2-4028-b1f5-0f581ab106bc"
      },
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Replace with the direct URL to the raw zip file content on GitHub\n",
        "# You can usually get this by going to the zip file on GitHub, clicking \"Raw\", and copying the URL\n",
        "zip_file_url = 'https://github.com/Harish-lvrk/Data-Analysis-project/raw/main/stack-overflow-developer-survey-2020%20(1).zip'\n",
        "local_zip_path = '/content/downloaded_file.zip'\n",
        "\n",
        "try:\n",
        "    # Download the zip file\n",
        "    response = requests.get(zip_file_url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    with open(local_zip_path, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "\n",
        "    print(f\"Zip file downloaded to {local_zip_path}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading zip file: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file downloaded to /content/downloaded_file.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Code\n",
        "\n",
        "1. **Importing Libraries**\n",
        "\n",
        "   * `requests` is used to make HTTP requests and download files from the internet.\n",
        "   * `os` is imported for handling file paths (though not used much here).\n",
        "\n",
        "2. **File URL and Destination Path**\n",
        "\n",
        "   * `zip_file_url` contains the direct download link of the zip file stored in GitHub.\n",
        "   * `local_zip_path` specifies the location where the file will be saved locally (here, in the Colab environment under `/content/`).\n",
        "\n",
        "3. **Making the Request**\n",
        "\n",
        "   * `requests.get(zip_file_url, stream=True)` sends a GET request to the URL and enables streaming, which means the file will be downloaded in chunks rather than loading it entirely into memory. This helps when downloading large files.\n",
        "\n",
        "4. **Checking the Response**\n",
        "\n",
        "   * `response.raise_for_status()` checks if the request was successful (status code 200). If not, it raises an error.\n",
        "\n",
        "5. **Saving the File**\n",
        "\n",
        "   * `with open(local_zip_path, 'wb') as f:` opens a new file in **write-binary mode (`wb`)**. Binary mode is necessary since we are writing raw bytes of a zip file, not text.\n",
        "   * The `with` statement ensures that the file is properly closed after writing, even if an error occurs.\n",
        "\n",
        "6. **Writing in Chunks**\n",
        "\n",
        "   * The `for chunk in response.iter_content(chunk_size=8192):` loop reads the file data in small pieces (8 KB each) instead of loading the whole file at once.\n",
        "   * `f.write(chunk)` writes each chunk to the file until the entire file is downloaded.\n",
        "\n",
        "7. **Success Message**\n",
        "\n",
        "   * If everything goes well, it prints the location of the saved zip file.\n",
        "\n",
        "8. **Error Handling**\n",
        "\n",
        "   * `except requests.exceptions.RequestException as e:` catches errors related to the HTTP request (e.g., wrong URL, network error).\n",
        "   * `except Exception as e:` catches any other unexpected errors and prints them.\n"
      ],
      "metadata": {
        "id": "3Q_cfO3Kp0aO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Sd_xkhz9m3iS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daf57b07",
        "outputId": "a47d6e19-3a5f-4b06-aefe-a757a36230f9"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "# Use the path where the file was downloaded by the previous cell\n",
        "local_zip_path = '/content/downloaded_file.zip'\n",
        "extract_path = '/content/extracted_data'\n",
        "\n",
        "try:\n",
        "    # Create the extraction directory if it doesn't exist\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "    # Open and extract the zip file\n",
        "    with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"Zip file extracted to {extract_path}\")\n",
        "\n",
        "    # List the files in the extracted directory\n",
        "    print(\"\\nFiles in the zip file:\")\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        for name in files:\n",
        "            print(os.path.join(root, name))\n",
        "        for name in dirs:\n",
        "            print(os.path.join(root, name))\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Zip file not found at {local_zip_path}. Please ensure the file path is correct and the previous cell ran successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error extracting zip file: {e}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file extracted to /content/extracted_data\n",
            "\n",
            "Files in the zip file:\n",
            "/content/extracted_data/so_survey_2020.pdf\n",
            "/content/extracted_data/README_2020.txt\n",
            "/content/extracted_data/survey_results_public.csv\n",
            "/content/extracted_data/survey_results_schema.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75be2afe"
      },
      "source": [
        "### Explanation of Zip Extraction Process\n",
        "\n",
        "1. **Importing Libraries**\n",
        "\n",
        "   * `zipfile` is used to work with ZIP archive files.\n",
        "   * `os` is used to manage file paths and directories.\n",
        "\n",
        "2. **Setting File Paths**\n",
        "\n",
        "   * `local_zip_path` stores the location where the ZIP file was downloaded in the previous step.\n",
        "   * `extract_path` specifies the folder where the contents of the ZIP file will be extracted.\n",
        "\n",
        "3. **Creating Extraction Directory**\n",
        "\n",
        "   * `os.makedirs(extract_path, exist_ok=True)` ensures the target folder exists. If it doesn‚Äôt, it creates it. If it already exists, no error is raised (because of `exist_ok=True`).\n",
        "\n",
        "4. **Opening and Extracting the Zip File**\n",
        "\n",
        "   * `with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:` opens the ZIP file in read mode.\n",
        "   * `zip_ref.extractall(extract_path)` extracts all contents of the ZIP file into the given directory.\n",
        "\n",
        "5. **Listing Extracted Files**\n",
        "\n",
        "   * `os.walk(extract_path)` is used to go through all files and subfolders inside the extracted directory.\n",
        "   * It prints the paths of both files and folders inside the extracted directory so you can verify the contents.\n",
        "\n",
        "6. **Error Handling**\n",
        "\n",
        "   * `FileNotFoundError`: Triggered if the ZIP file does not exist at the given path.\n",
        "   * `Exception as e`: Catches any other unexpected errors during extraction.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **Summary:** This code safely extracts the downloaded ZIP file into a specified folder, ensures the folder exists before extraction, and lists all files and folders inside it. It also includes error handling for missing files or unexpected issues.\n",
        "The `for` loop with `os.walk(extract_path)` goes through the folder where the ZIP file was extracted and lists out everything inside it. Let‚Äôs break it step by step:\n",
        "\n",
        "1. **`os.walk(extract_path)`**\n",
        "\n",
        "   * This function goes through the folder (`extract_path`) and gives three things for each directory it visits:\n",
        "\n",
        "     * `root` ‚Üí The current folder path.\n",
        "     * `dirs` ‚Üí A list of all sub-folders inside the current folder.\n",
        "     * `files` ‚Üí A list of all files inside the current folder.\n",
        "\n",
        "2. **First inner loop (`for name in files:`)**\n",
        "\n",
        "   * It goes through every file found in that folder.\n",
        "   * `os.path.join(root, name)` combines the folder path (`root`) with the file name (`name`) to get the full file path.\n",
        "   * `print(...)` then shows the full path of each file.\n",
        "\n",
        "3. **Second inner loop (`for name in dirs:`)**\n",
        "\n",
        "   * It goes through every sub-folder found inside that folder.\n",
        "   * Again, `os.path.join(root, name)` creates the full path of the folder.\n",
        "   * `print(...)` then shows the full path of each folder.\n",
        "\n",
        "üëâ In your case, there were **no sub-folders**, only files, so only the file paths were printed.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "FQ2MWrchscXk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema_data = pd.read_csv('/content/extracted_data/survey_results_schema.csv')\n",
        "df = pd.read_csv('/content/extracted_data/survey_results_public.csv')"
      ],
      "metadata": {
        "id": "rYWU0WGRuOlx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESDiUVmqubFq",
        "outputId": "50163c49-62ff-4a9d-cfc0-b0ec66e37d17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a76615bf"
      },
      "source": [
        "This code cell uses the `.shape` attribute of the `schema_data` pandas DataFrame.\n",
        "\n",
        "- `.shape` returns a tuple representing the dimensions of the DataFrame.\n",
        "- The output `(61, 2)` indicates that the `schema_data` DataFrame has 61 rows and 2 columns."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQL8Sjgd0-Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema.info()"
      ],
      "metadata": {
        "id": "pDfXAEdL0un6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96b13f94"
      },
      "source": [
        "This code cell loads two CSV files into pandas DataFrames:\n",
        "\n",
        "- `schema_data = pd.read_csv('/content/extracted_data/survey_results_schema.csv')`: This line reads the `survey_results_schema.csv` file, which likely contains information about each column in the main survey data, into a DataFrame named `schema_data`.\n",
        "- `df = pd.read_csv('/content/extracted_data/survey_results_public.csv')`: This line reads the main survey data from `survey_results_public.csv` into a DataFrame named `df`. This is the primary DataFrame you will likely use for your analysis.\n",
        "\n",
        "Both files are read from the `/content/extracted_data/` directory where the zip file was extracted."
      ]
    }
  ]
}